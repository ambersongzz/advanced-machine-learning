{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Q1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Q2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read IMDB dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'aclImdb/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "def read_file_from_folders(path, folders):\n",
    "    X = []\n",
    "    y = []\n",
    "    for folder in folders:\n",
    "        files = (glob.glob(path + folder + \"/*.txt\"))\n",
    "        for file in files:\n",
    "            f = open(file, 'r')\n",
    "            X.append(f.read())\n",
    "            y.append(folder)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y = read_file_from_folders('aclImdb/train/', ['neg', 'pos'])\n",
    "test_X, test_y = read_file_from_folders('aclImdb/test/', ['neg', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\",\n",
       " 'neg')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0], test_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the libary spacy to tokenize your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "import re\n",
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# borrowed from fast.ai (https://github.com/fastai/fastai/blob/master/fastai/nlp.py)\n",
    "\n",
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Story', 'of', 'a', 'man', 'who', 'has', 'unnatural', 'feelings', 'for', 'a', 'pig', '.', 'Starts', 'out', 'with', 'a', 'opening', 'scene', 'that', 'is', 'a', 'terrific', 'example', 'of', 'absurd', 'comedy', '.', 'A', 'formal', 'orchestra', 'audience', 'is', 'turned', 'into', 'an', 'insane', ',', 'violent', 'mob', 'by', 'the', 'crazy', 'chantings', 'of', 'it', \"'s\", 'singers', '.', 'Unfortunately', 'it', 'stays', 'absurd', 'the', 'WHOLE', 'time', 'with', 'no', 'general', 'narrative', 'eventually', 'making', 'it', 'just', 'too', 'off', 'putting', '.', 'Even', 'those', 'from', 'the', 'era', 'should', 'be', 'turned', 'off', '.', 'The', 'cryptic', 'dialogue', 'would', 'make', 'Shakespeare', 'seem', 'easy', 'to', 'a', 'third', 'grader', '.', 'On', 'a', 'technical', 'level', 'it', \"'s\", 'better', 'than', 'you', 'might', 'think', 'with', 'some', 'good', 'cinematography', 'by', 'future', 'great', 'Vilmos', 'Zsigmond', '.', 'Future', 'stars', 'Sally', 'Kirkland', 'and', 'Frederic', 'Forrest', 'can', 'be', 'seen', 'briefly', '.']\n"
     ]
    }
   ],
   "source": [
    "print(spacy_tok(train_X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the 300 dimensional Glove embeddings into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'glove.6B/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove = {}\n",
    "glove = dict([(line.split(' ')[0], line.split(' ')[1:]) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# output = open('glove.pkl', 'wb')\n",
    "# # Pickle dictionary using protocol 0.\n",
    "# pickle.dump(glove, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pkl_file = open('glove.pkl', 'rb')\n",
    "# glove = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create average feature embedding for each sentence. You may want to ignore stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/zsong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# get stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_non_stopwords(text):\n",
    "    \"\"\"Returns a list of non-stopwords\"\"\"\n",
    "    return [x for x in spacy_tok(str(text).lower()) if x not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_feature_embedding(text):\n",
    "    l = [glove[word.lower()] for word in get_non_stopwords(text) if word.lower() in glove]\n",
    "    l_np = np.array(l, dtype = float)\n",
    "    return l_np.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X_embedding = np.array([sentence_feature_embedding(text) for text in train_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X_embedding = np.array([sentence_feature_embedding(text) for text in test_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 300), (25000, 300))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_embedding.shape, test_X_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an XGBoost classifier to this data. Report test and training errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode labels in trainig and test set\n",
    "train_y_encoding = np.array([0 if label == 'neg' else 1 for label in train_y])\n",
    "test_y_encoding = np.array([0 if label == 'neg' else 1 for label in test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.random.choice(np.arange(0,2), size = len(train_y_encoding), p=[0.2, 0.8]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4949, 20051)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y_encoding[index==0]), len(train_y_encoding[index==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_X_embedding[index==1], label=train_y_encoding[index==1])\n",
    "dval = xgb.DMatrix(train_X_embedding[index==0], label=train_y_encoding[index==0])\n",
    "dtest = xgb.DMatrix(test_X_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20051, 300)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.num_row(), dtrain.num_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'n_estimators': 1000, 'max_depth': 5, 'eta': 0.1, \n",
    "         'subsample': 0.8, 'objective': 'binary:logistic', 'eval_metric': 'logloss'}\n",
    "evallist = [(dtrain, 'train'), (dval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.671225\teval-logloss:0.674822\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.278835\teval-logloss:0.419124\n",
      "[200]\ttrain-logloss:0.183175\teval-logloss:0.396528\n",
      "[300]\ttrain-logloss:0.128021\teval-logloss:0.392063\n",
      "[400]\ttrain-logloss:0.090805\teval-logloss:0.393611\n",
      "Stopping. Best iteration:\n",
      "[358]\ttrain-logloss:0.104611\teval-logloss:0.391316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, dtrain, 3000, evals = evallist, early_stopping_rounds=100, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.03736\n",
      "test error: 0.17548\n"
     ]
    }
   ],
   "source": [
    "pred_train = np.rint(bst.predict(xgb.DMatrix(train_X_embedding)))\n",
    "print('training error:', np.mean(pred_train != train_y_encoding))\n",
    "pred_test = np.rint(bst.predict(dtest))\n",
    "print('test error:', np.mean(pred_test != test_y_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare previous results to fitting XGBoost to a one-hot encoding representation of the data with bag of words. Report test and training errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "train_X_bag = count.fit_transform(train_X)\n",
    "test_X_bag = count.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74849)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_bag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_X_bag[index==1], label=train_y_encoding[index==1])\n",
    "dval = xgb.DMatrix(train_X_bag[index==0], label=train_y_encoding[index==0])\n",
    "dtest = xgb.DMatrix(test_X_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'n_estimators': 1000, 'max_depth': 5, 'eta': 0.1, \n",
    "         'subsample': 0.8, 'objective': 'binary:logistic', 'eval_metric': 'logloss'}\n",
    "evallist = [(dtrain, 'train'), (dval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.672246\teval-logloss:0.674428\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.350439\teval-logloss:0.415533\n",
      "[200]\ttrain-logloss:0.27044\teval-logloss:0.36695\n",
      "[300]\ttrain-logloss:0.222477\teval-logloss:0.340979\n",
      "[400]\ttrain-logloss:0.189219\teval-logloss:0.325838\n",
      "[500]\ttrain-logloss:0.164099\teval-logloss:0.315921\n",
      "[600]\ttrain-logloss:0.143449\teval-logloss:0.31\n",
      "[700]\ttrain-logloss:0.126529\teval-logloss:0.305443\n",
      "[800]\ttrain-logloss:0.112552\teval-logloss:0.302111\n",
      "[900]\ttrain-logloss:0.099925\teval-logloss:0.300357\n",
      "[1000]\ttrain-logloss:0.089901\teval-logloss:0.298878\n",
      "[1100]\ttrain-logloss:0.080632\teval-logloss:0.29832\n",
      "[1200]\ttrain-logloss:0.072626\teval-logloss:0.297326\n",
      "Stopping. Best iteration:\n",
      "[1191]\ttrain-logloss:0.07368\teval-logloss:0.296913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, dtrain, 3000, evals = evallist, early_stopping_rounds=100, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.0298\n",
      "test error: 0.1244\n"
     ]
    }
   ],
   "source": [
    "pred_train = np.rint(bst.predict(xgb.DMatrix(train_X_bag)))\n",
    "print('training error:',np.mean(pred_train != train_y_encoding))\n",
    "pred_test = np.rint(bst.predict(dtest))\n",
    "print('test error:',np.mean(pred_test != test_y_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error(0.17548) of word embedding XGBoost is higher than the test error(0.1244) of one-hot encoding XGBoost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
